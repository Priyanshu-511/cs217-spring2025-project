{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Mounting My Drive for the files**"
      ],
      "metadata": {
        "id": "UwVFJL2yVM7n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stilhtxaKK5m",
        "outputId": "5e90aa2f-531f-478b-e20a-dcce9bea9f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Dataset link : https://drive.google.com/file/d/1LLFx4aEELA5PTbVMyARZATrQ5fJON5Pw/view?usp=drive_link"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Packages**"
      ],
      "metadata": {
        "id": "ciX6QHKbVZDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "!pip install gradio\n",
        "import gradio as gr\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RRig6MMKhUq",
        "outputId": "75615817-1339-475f-a17d-8c4be453b103"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.29.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.17)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.8)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining The Neural BPR Model**"
      ],
      "metadata": {
        "id": "6cZ90oIiVhEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Model Definition ----------\n",
        "class NBPR(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_dim=20, hidden_dims=[64,32], reg=1e-4):\n",
        "        super().__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_dim)\n",
        "        layers = []\n",
        "        input_dim = emb_dim * 2\n",
        "        for h in hidden_dims:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.ReLU())\n",
        "            input_dim = h\n",
        "        layers.append(nn.Linear(input_dim, 1))\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.reg = reg\n",
        "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
        "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
        "\n",
        "    def forward(self, user, item):\n",
        "        p = self.user_emb(user)\n",
        "        q = self.item_emb(item)\n",
        "        x = torch.cat([p, q], dim=1)\n",
        "        return self.mlp(x).squeeze()\n",
        "\n",
        "    def bpr_loss(self, u, i, j):\n",
        "        r_ui = self(u, i)\n",
        "        r_uj = self(u, j)\n",
        "        loss = -F.logsigmoid(r_ui - r_uj).mean()\n",
        "        reg_term = (self.user_emb(u).pow(2).sum() +\n",
        "                    self.item_emb(i).pow(2).sum() +\n",
        "                    self.item_emb(j).pow(2).sum())\n",
        "        for param in self.mlp.parameters():\n",
        "            reg_term += param.pow(2).sum()\n",
        "        return loss + self.reg * reg_term\n"
      ],
      "metadata": {
        "id": "Vtw9hkCcLKMu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting The Data Ready**"
      ],
      "metadata": {
        "id": "8UW8EVS0VoAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Data Preparation ----------\n",
        "# data.csv location : https://drive.google.com/file/d/1LLFx4aEELA5PTbVMyARZATrQ5fJON5Pw/view?usp=drive_link\n",
        "def get_song_indices(names, df):\n",
        "    indices = []\n",
        "    for name in names:\n",
        "        name = name.strip().lower()\n",
        "        matches = df.index[df['name'].str.lower() == name].tolist()\n",
        "        if matches:\n",
        "            indices.append(matches[0])\n",
        "    return list(set(indices))\n",
        "# If downloading dataset, please replace filepath with data.csv\n",
        "def load_and_preprocess():\n",
        "    df = pd.read_csv('/content/drive/MyDrive/data.csv').dropna().reset_index(drop=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "VdpZASTMLX7L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recommendation System**"
      ],
      "metadata": {
        "id": "PD64cUCdVzEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Modified Recommender System ----------\n",
        "class RecommenderSystem:\n",
        "    def __init__(self):\n",
        "        self.df = load_and_preprocess()\n",
        "        self.num_items = len(self.df)\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    def train_on_input(self, input_songs, epochs=100):\n",
        "        user_pos = get_song_indices(input_songs, self.df)\n",
        "\n",
        "        # If no valid song was found, return early\n",
        "        if not user_pos:\n",
        "            return None\n",
        "\n",
        "        # Initialize a new model each time\n",
        "        model = NBPR(1, self.num_items).to(self.device)\n",
        "        opt = optim.Adam(model.parameters(), lr=1e-3)\n",
        "        neg_pool = list(set(range(self.num_items)) - set(user_pos))\n",
        "\n",
        "        # Quick training loop\n",
        "        for epoch in range(epochs):\n",
        "            batch_size = min(512, len(user_pos) * 10)  # Adjust batch size based on input\n",
        "            u = torch.zeros(batch_size, dtype=torch.long, device=self.device)\n",
        "            i = torch.tensor(np.random.choice(user_pos, batch_size, replace=True), device=self.device)\n",
        "            j = torch.tensor(np.random.choice(neg_pool, batch_size), device=self.device)\n",
        "\n",
        "            loss = model.bpr_loss(u, i, j)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        return model\n",
        "\n",
        "    def recommend(self, user_input, temperature=1.0, top_k=20):\n",
        "        input_songs = [s.strip() for s in user_input.split(\",\") if s.strip()]\n",
        "\n",
        "        # Train model on user input\n",
        "        model = self.train_on_input(input_songs)\n",
        "\n",
        "        # If no valid songs were found, return empty DataFrame\n",
        "        if model is None:\n",
        "            return pd.DataFrame(columns=[\"Song\", \"Artist\", \"Score\", \"Probability\"])\n",
        "\n",
        "        exclude_indices = get_song_indices(input_songs, self.df)\n",
        "\n",
        "        # Generate recommendations\n",
        "        with torch.no_grad():\n",
        "            u = torch.zeros(self.num_items, dtype=torch.long, device=self.device)\n",
        "            items = torch.arange(self.num_items, device=self.device)\n",
        "            scores = model(u, items).cpu().numpy()\n",
        "\n",
        "        # Apply temperature scaling\n",
        "        scores[exclude_indices] = -np.inf\n",
        "        valid_scores = scores.copy()\n",
        "        valid_scores[exclude_indices] = -np.inf\n",
        "\n",
        "        # Convert to probabilities using softmax with temperature\n",
        "        exp_scores = np.exp(valid_scores / temperature)\n",
        "        probs = exp_scores / exp_scores.sum()\n",
        "\n",
        "        # Sample without replacement using PyTorch multinomial\n",
        "        valid_indices = np.where(valid_scores != -np.inf)[0]\n",
        "\n",
        "        if len(valid_indices) == 0:\n",
        "            return pd.DataFrame(columns=[\"Song\", \"Artist\", \"Score\", \"Probability\"])\n",
        "\n",
        "        sampled_indices = torch.multinomial(\n",
        "            torch.tensor(probs[valid_indices], dtype=torch.float32),\n",
        "            num_samples=min(top_k, len(valid_indices)),\n",
        "            replacement=False\n",
        "        ).numpy()\n",
        "\n",
        "        # Get final recommendations\n",
        "        top_indices = valid_indices[sampled_indices]\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            song = self.df.iloc[idx]\n",
        "            results.append({\n",
        "                \"Song\": song['name'],\n",
        "                \"Artist\": song['artists'],\n",
        "                \"Score\": f\"{scores[idx]:.4f}\",\n",
        "                \"Probability\": f\"{probs[idx]:.4f}\"\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "Hy3zIFm4Lk-k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Putting It All Together and Gradio Interface**"
      ],
      "metadata": {
        "id": "dEX7vn7BV-fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize recommender system\n",
        "    rs = RecommenderSystem()\n",
        "\n",
        "    # Create Gradio interface with controls\n",
        "    with gr.Blocks(title=\"Dynamic Song Recommender\") as demo:\n",
        "        gr.Markdown(\"# ðŸŽµ Dynamic Song Recommender\")\n",
        "        gr.Markdown(\"Enter songs you like and adjust parameters for diverse recommendations\")\n",
        "\n",
        "        with gr.Row():\n",
        "            song_input = gr.Textbox(\n",
        "                label=\"Your favorite songs (comma separated)\",\n",
        "                placeholder=\"e.g.: Shape of You, Bohemian Rhapsody\"\n",
        "            )\n",
        "            with gr.Column():\n",
        "                temperature = gr.Slider(0.1, 2.0, value=0.5,\n",
        "                                      label=\"Diversity Control (Temperature)\")\n",
        "                top_k = gr.Slider(5, 50, value=20, step=1,\n",
        "                                label=\"Number of Recommendations\")\n",
        "\n",
        "        recommend_btn = gr.Button(\"Generate Recommendations\")\n",
        "        output_df = gr.DataFrame(\n",
        "            headers=[\"Song\", \"Artist\", \"Score\", \"Probability\"],\n",
        "            label=\"Recommended Songs\"\n",
        "        )\n",
        "\n",
        "        recommend_btn.click(\n",
        "            fn=rs.recommend,\n",
        "            inputs=[song_input, temperature, top_k],\n",
        "            outputs=output_df\n",
        "        )\n",
        "\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "PhUxAsvKLpPY",
        "outputId": "7d97b139-f359-458a-bc09-a57f5fcff5e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b72f8b0649a0d79670.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b72f8b0649a0d79670.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}